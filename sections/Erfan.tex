\section{general}
\subsection{2016 - An image-based visual servo control system based on an eye-in-hand monocular camera for autonomous robotic grasping}
\begin{itemize}
\item No use of interaction matrix as traditional method
\item In visual servo system, information from a vision system is used as feedback signals in a closed-loop control system to control robot motion in real-time [1]
\item An eye-to-hand camera is installed beside robot while an eye-in-hand camera is mounted on end-effector [2]
\item An eye-to-hand removes problems associated with a moving camera however it may have some issues such as the camera-to-robot coordinate transformation, manipulator occlude interested features and calibration arise [3]. 
\item An eye-in-hand camera can change vision position so that the coordinate transformation is relatively simple however it suffers from some problem such as interested features is outside from the field of view while a camera is moving.
\item Traditional image-based visual servo needs to know an interaction matrix. 
\item  Our method is based on the point error, area error of features and simple depth estimation
\item A key parameter to determine an interaction matrix is the depth value for each feature point in each iteration of control loop. Therefore, many researchers use a stereo camera to determine every depth values for each feature point immediately. [4] 
\item In some research works [6] they used monocular camera and interaction matrix without changing the pitch and roll of camera and interested features.They also estimate depth value from Kalman Filter.
\item In some work [7], they used monocular camera and estimate interaction matrix from
Kalman-neural-network filtering. 
\item In addition, Kosmopoulus [8] used monocular camera and estimate interaction matrix from local estimation.
\end{itemize}
1: \textit{2000 - A new hybrid image-based visual servo control scheme} \\
2: \textit{2015 - Position-based visual servo control of autonomous robotic manipulators} \\
3: \textit{1996 - Vision-guided robotic grasping: issues and experiments} \\
4: \textit{2014 - A modified image-based visual servo controller with hybrid camera configuration for robust robotic grasping,} \\
5: \textit{2012 - Combining stereo vision and fuzzy image based visual servoing for autonomous object grasping using a 6-DOF manipulator} \\
6: \textit{2014 - Hybrid Eye-to-hand and Eye-in-hand visual servo system for parallel robot conveyor object tracking and fetching} \\
7: \textit{2015 - Robots visual servo control with features constraint employing Kalman-neural-network filtering scheme} \\
8: \textit{2011 - Robust Jacobian matrix estimation for image-based
visual servoing}


\section{High-speed tracking}
\subsection{2016 - High-speed 3-D measurement of a moving object with visual servo}
\begin{itemize}
\item A robot equipped with a stereo camera was able to perform the motions needed to prepare coffee and to catch thrown balls. [1]
\item To catch flying objects, it is necessary not only to estimate the trajectories of the objects in a short time but also to rapidly and accurately control the motion of robot arms.
\item In some works such as [2] and [3] robot could catch flying objects of various forms, such as a plastic bottle, a tennis racket, and a brick, by estimating the trajectories via machine learning, but recognition of the type of object requires markers to be attached to the object
\item Quick manipulation via high-speed stereo vision system that can measure the 3-D centroid position of a target at 500 frames per second. Dexterous actions, such as juggling and kendama catching motions [4], [5]. But, difficult to handle an object with a complex shape.
\item  We have developed a system in which a high-speed 3-D sensor is mounted on a 2-axis active vision system. As a result, the measurement range becomes wider, and 3-D recognition of a
rapidly moving object becomes more accurate because rapid
tracking
\end{itemize}
1: \textit{2011 -  Catching flying balls and preparing coffee: humanoid RollinfJustin performs dynamic and sensitive tasks} \{\ref{humanoid}\} \\
2: \textit{2014 -  Catching Objects in Flight} \\
3: \textit{2016 - A dynamical system
approach for softly catching a flying object: theory and experiment} \\
4: \textit{2012 - Two ball
juggling with high-speed hand-arm and high-speed vision system} \\
5: \textit{2014 - Ball catching in kendama game by estimating
grasp conditions based on a high-speed vision system and tactile
sensors}

\section{Nanorobotic manipulation}
\subsection{2017 - A Vision-based Automated Manipulation System for the Pick-up of Carbon Nanotubes}
\begin{itemize}
\item A nanorobotic manipulation system allowing automated pick-up of carbon nanotube (CNT) based on visual feedback.
\item Histogram thresholding for automatic binarization... clearly distinguished CNTs from the substrate and other impurities under various image brightnesses and contrasts.
\item Segment detection method (SDM) to separate the CNT
and AFM cantilever during overlapping.
\item Delicate manipulation of CNTs is a large challenge because CNTs are generated in bulk.
\item Conventionally, the manipulation of nanomaterials is manually performed through teleoperation which is time consuming, highly skill dependent and unproductive. [1]
\item Visual feedback-based nanorobotic manipulation
provides an effective way to overcome these shortcomings. 
\item Great progress to visually detect the position
of such nanomaterials, such as [2] which uses the principle component analysis (PCA) to locate CNTs
\item Great efforts have been made to obtain the relative depth information from SEM such as [3]. The observation and manipulation of nano scale objects under SEM
\end{itemize}
1: \textit{2013 - Automated pickplace of silicon nanowires} \\
2: \textit{2009 - Nanolab: A nanorobotic system for automated pick-and-place handling and characterization of cnts} \\
3: \textit{2013 - A measurement method for micro 3d shape
based on grids-processing and stereovision technology}


\section{Aerial manipulation}
\subsection{2017 - Uncalibrated Visual Servo for Unmanned Aerial Manipulation}
\begin{itemize}
\item An uncalibrated image-based visual servo strategy to drive the arm end-effector to a desired position and orientation using a camera attached to it. 
\item In contrast to previous visual-servo approaches, a known value of camera focal length is not strictly required. 
\item Vision-based robot control systems are usually classified in three groups: position-based visual servo (PBVS) (the geometric model of the target is used in conjunction with image features to estimate the pose of the target with respect to the camera frame), image-based visual servo (IBVS) (both the error and control law are expressed in the image space, minimizing the error between observed and desired image feature coordinates), and hybrid control systems [1].
\item IBVS is more robust than PBVS with respect to uncertainties and disturbances affecting the model of the robot, as well as the calibration of the camera [2]
\item  Hybrid methods, also called 2-1/2-D visual servo [3], combine IBVS and PBVS to estimate partial camera displacements at each iteration of the control law minimizing a functional of both.
\item In our method, the camera focal length is iteratively estimated within the control loop.
\item In contrast to [4] which uses a combination of classical PBVS and IBVS, in this article we present a fully vision-based self-calibrated scheme that can handle poorly calibrated cameras.
\end{itemize}
1: \textit{2011 - Comparison of basic visual servoing methods} \\
2: \textit{2003 - â€œRobustness of image-based visual servoing with respect to depth distribution errors} \\
3: \textit{1999 - 2-1/2-D visual servoing} \\
4: \textit{2016 - Hybrid visual servoing with hierarchical task composition for aerial manipulation}


\subsection{2016 - Vision Based Autonomous Orientational Control for Aerial Manipulation via On-board FPGA}

\subsection{2016 - Vision-Guided Aerial Manipulation Using a Multirotor With a Robotic Arm}

\section{Humanoid} \label{humanoid}
\subsection{2016 - Vision-based manipulation with the humanoid robot Romeo}

\section{Dexterous}
\subsection{2016 - Vision-based precision manipulation with underactuated hands: Simple and effective solutions for dexterity}


\section{Teleoperation}
\subsection{2016 - Vision based virtual fixture generation for teleoperated robotic manipulation}


\section{Underwater}
\subsection{2016 - Underwater vehicle visual servo and target grasp control}


\section{Multi-robot}
\subsection{2016 - Image based adaptive coordinated control for cooperative manipulators}
\begin{itemize}
\item Two ways to build up a vision system: Eye in hand such as [1], and eye to hand such as [2]
\item in [3], an adaptive visual servo method is designed for trajectory tracking by decomposing the depth-independent Jacobian matrix. Here, uncertainties in kinematics and dynamics of robot manipulators are considered. 
\item visual tracking control method for the cooperative robot system is designed. 
\end{itemize}
1: \textit{2011 - A new approach to dynamic eye-in-hand visual tracking using non-linear observer} \\
2: \textit{2012 - Visual servoing of robots with uncalibrated robot and camera parameters} \\
3: \textit{2015 - Adaptive visual tracking for robotic systems without image space velocity measurement}

