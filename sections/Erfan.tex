\section{Nanorobotic manipulation}
\subsection{2017 - A Vision-based Automated Manipulation System for the Pick-up of Carbon Nanotubes}
\begin{itemize}
\item A nanorobotic manipulation system allowing automated pick-up of carbon nanotube (CNT) based on visual feedback.
\item Histogram thresholding for automatic binarization... clearly distinguished CNTs from the substrate and other impurities under various image brightnesses and contrasts.
\item Segment detection method (SDM) to separate the CNT
and AFM cantilever during overlapping.
\item Delicate manipulation of CNTs is a large challenge because CNTs are generated in bulk.
\item Conventionally, the manipulation of nanomaterials is manually performed through teleoperation which is time consuming, highly skill dependent and unproductive. [1]
\item Visual feedback-based nanorobotic manipulation
provides an effective way to overcome these shortcomings. 
\item Great progress to visually detect the position
of such nanomaterials, such as [2] which uses the principle component analysis (PCA) to locate CNTs
\item Great efforts have been made to obtain the relative depth information from SEM such as [3]. The observation and manipulation of nano scale objects under SEM
\end{itemize}
1: \textit{2013 - Automated pickplace of silicon nanowires} \\
2: \textit{2009 - Nanolab: A nanorobotic system for automated pick-and-place handling and characterization of cnts} \\
3: \textit{2013 - A measurement method for micro 3d shape
based on grids-processing and stereovision technology}


\section{Aerial manipulation}
\subsection{2017 - Uncalibrated Visual Servo for Unmanned Aerial Manipulation}
\begin{itemize}
\item An uncalibrated image-based visual servo strategy to drive the arm end-effector to a desired position and orientation using a camera attached to it. 
\item In contrast to previous visual-servo approaches, a known value of camera focal length is not strictly required. 
\item Vision-based robot control systems are usually classified in three groups: position-based visual servo (PBVS) (the geometric model of the target is used in conjunction with image features to estimate the pose of the target with respect to the camera frame), image-based visual servo (IBVS) (both the error and control law are expressed in the image space, minimizing the error between observed and desired image feature coordinates), and hybrid control systems [1].
\item IBVS is more robust than PBVS with respect to uncertainties and disturbances affecting the model of the robot, as well as the calibration of the camera [2]
\item  Hybrid methods, also called 2-1/2-D visual servo [3], combine IBVS and PBVS to estimate partial camera displacements at each iteration of the control law minimizing a functional of both.
\item In our method, the camera focal length is iteratively estimated within the control loop.
\item In contrast to [4] which uses a combination of classical PBVS and IBVS, in this article we present a fully vision-based self-calibrated scheme that can handle poorly calibrated cameras.
\end{itemize}
1: \textit{2011 - Comparison of basic visual servoing methods} \\
2: \textit{2003 - â€œRobustness of image-based visual servoing with respect to depth distribution errors} \\
3: \textit{1999 - 2-1/2-D visual servoing} \\
4: \textit{2016 - Hybrid visual servoing with hierarchical task composition for aerial manipulation}


\subsection{2016 - Vision Based Autonomous Orientational Control for Aerial Manipulation via On-board FPGA}

\section{Humanoid}
\subsection{2016 - Vision-based manipulation with the humanoid robot Romeo}

\section{Dexterous}
\subsection{2016 - Vision-based precision manipulation with underactuated hands: Simple and effective solutions for dexterity}