\section{general}
\subsection{2016 - An image-based visual servo control system based on an eye-in-hand monocular camera for autonomous robotic grasping}

\section{High-speed tracking}
\subsection{2016 - High-speed 3-D measurement of a moving object with visual servo}
\begin{itemize}
\item A robot equipped with a stereo camera was able to perform the motions needed to prepare coffee and to catch thrown balls. [1]
\item To catch flying objects, it is necessary not only to estimate the trajectories of the objects in a short time but also to rapidly and accurately control the motion of robot arms.
\item In some works such as [2] and [3] robot could catch flying objects of various forms, such as a plastic bottle, a tennis racket, and a brick, by estimating the trajectories via machine learning, but recognition of the type of object requires markers to be attached to the object
\item Quick manipulation via high-speed stereo vision system that can measure the 3-D centroid position of a target at 500 frames per second. Dexterous actions, such as juggling and kendama catching motions [4], [5]. But, difficult to handle an object with a complex shape.
\item  We have developed a system in which a high-speed 3-D sensor is mounted on a 2-axis active vision system. As a result, the measurement range becomes wider, and 3-D recognition of a
rapidly moving object becomes more accurate because rapid
tracking
\end{itemize}
1: \textit{2011 -  Catching flying balls and preparing coffee: humanoid RollinfJustin performs dynamic and sensitive tasks} \{\ref{humanoid}\} \\
2: \textit{2014 -  Catching Objects in Flight} \\
3: \textit{2016 - A dynamical system
approach for softly catching a flying object: theory and experiment} \\
4: \textit{2012 - Two ball
juggling with high-speed hand-arm and high-speed vision system} \\
5: \textit{2014 - Ball catching in kendama game by estimating
grasp conditions based on a high-speed vision system and tactile
sensors}

\section{Nanorobotic manipulation}
\subsection{2017 - A Vision-based Automated Manipulation System for the Pick-up of Carbon Nanotubes}
\begin{itemize}
\item A nanorobotic manipulation system allowing automated pick-up of carbon nanotube (CNT) based on visual feedback.
\item Histogram thresholding for automatic binarization... clearly distinguished CNTs from the substrate and other impurities under various image brightnesses and contrasts.
\item Segment detection method (SDM) to separate the CNT
and AFM cantilever during overlapping.
\item Delicate manipulation of CNTs is a large challenge because CNTs are generated in bulk.
\item Conventionally, the manipulation of nanomaterials is manually performed through teleoperation which is time consuming, highly skill dependent and unproductive. [1]
\item Visual feedback-based nanorobotic manipulation
provides an effective way to overcome these shortcomings. 
\item Great progress to visually detect the position
of such nanomaterials, such as [2] which uses the principle component analysis (PCA) to locate CNTs
\item Great efforts have been made to obtain the relative depth information from SEM such as [3]. The observation and manipulation of nano scale objects under SEM
\end{itemize}
1: \textit{2013 - Automated pickplace of silicon nanowires} \\
2: \textit{2009 - Nanolab: A nanorobotic system for automated pick-and-place handling and characterization of cnts} \\
3: \textit{2013 - A measurement method for micro 3d shape
based on grids-processing and stereovision technology}


\section{Aerial manipulation}
\subsection{2017 - Uncalibrated Visual Servo for Unmanned Aerial Manipulation}
\begin{itemize}
\item An uncalibrated image-based visual servo strategy to drive the arm end-effector to a desired position and orientation using a camera attached to it. 
\item In contrast to previous visual-servo approaches, a known value of camera focal length is not strictly required. 
\item Vision-based robot control systems are usually classified in three groups: position-based visual servo (PBVS) (the geometric model of the target is used in conjunction with image features to estimate the pose of the target with respect to the camera frame), image-based visual servo (IBVS) (both the error and control law are expressed in the image space, minimizing the error between observed and desired image feature coordinates), and hybrid control systems [1].
\item IBVS is more robust than PBVS with respect to uncertainties and disturbances affecting the model of the robot, as well as the calibration of the camera [2]
\item  Hybrid methods, also called 2-1/2-D visual servo [3], combine IBVS and PBVS to estimate partial camera displacements at each iteration of the control law minimizing a functional of both.
\item In our method, the camera focal length is iteratively estimated within the control loop.
\item In contrast to [4] which uses a combination of classical PBVS and IBVS, in this article we present a fully vision-based self-calibrated scheme that can handle poorly calibrated cameras.
\end{itemize}
1: \textit{2011 - Comparison of basic visual servoing methods} \\
2: \textit{2003 - â€œRobustness of image-based visual servoing with respect to depth distribution errors} \\
3: \textit{1999 - 2-1/2-D visual servoing} \\
4: \textit{2016 - Hybrid visual servoing with hierarchical task composition for aerial manipulation}


\subsection{2016 - Vision Based Autonomous Orientational Control for Aerial Manipulation via On-board FPGA}

\subsection{2016 - Vision-Guided Aerial Manipulation Using a Multirotor With a Robotic Arm}

\section{Humanoid} \label{humanoid}
\subsection{2016 - Vision-based manipulation with the humanoid robot Romeo}

\section{Dexterous}
\subsection{2016 - Vision-based precision manipulation with underactuated hands: Simple and effective solutions for dexterity}


\section{Teleoperation}
\subsection{2016 - Vision based virtual fixture generation for teleoperated robotic manipulation}


\section{Underwater}
\subsection{2016 - Underwater vehicle visual servo and target grasp control}


\section{Multi-robot}
\subsection{2016 - Image based adaptive coordinated control for cooperative manipulators}

